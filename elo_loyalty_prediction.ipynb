{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to Predict Elo Customer Loyalty\n",
    "\n",
    "_Note! If you want to commit any changes to this document, please strip all output (Cell > Current Outputs > Clear, or set up [nbstripout](https://github.com/kynan/nbstripout) as a git filter) from this notebook before doing so. Thanks!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Next we import the Python libraries we'll need. If any of these are missing for you, you can install them with e.g. `pip3 install pandas` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the data into Pandas data frames and look at their structure.\n",
    "\n",
    "First thing we'll do with the training data is split it into a train and validation set. (The given test set is what we'll later make our predictions on and upload, but only after we are fully satisfied with our model.)\n",
    "\n",
    "**Make sure to run `make processdata` (which takes a very long time, but only needs to be done once) before running the code in this notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df = pd.read_csv('data/processed/historical_transactions.csv')\n",
    "merch_trans_df = pd.read_csv('data/processed/new_merchant_transactions_with_merchants.csv')\n",
    "train_and_validation_df = pd.read_csv('data/unzipped/train.csv',\n",
    "                                      index_col='card_id',\n",
    "                                      parse_dates=['first_active_month'])\n",
    "test_df = pd.read_csv('data/unzipped/test.csv',\n",
    "                      index_col='card_id',\n",
    "                      parse_dates=['first_active_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features\n",
    "\n",
    "Next we want to combine and shape all of our raw data to create useful features in the train (and validation and test) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.metrics import *\n",
    "from feature_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(train_and_validation_df, 'first_active_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.drop(['first_active_monthDay', 'first_active_monthDayofweek',\n",
    "                              'first_active_monthDayofyear', 'first_active_monthIs_month_end',\n",
    "                              'first_active_monthIs_month_start', 'first_active_monthIs_quarter_end',\n",
    "                              'first_active_monthIs_year_end'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(test_df, 'first_active_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['first_active_monthDay', 'first_active_monthDayofweek', 'first_active_monthDayofyear',\n",
    "              'first_active_monthIs_month_end', 'first_active_monthIs_month_start',\n",
    "              'first_active_monthIs_quarter_end', 'first_active_monthIs_year_end'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Transaction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the functions defined in `feature_engineering.py` to aggregate the historical transactions for each card into single values for that card, for instance the mean of all purchase amounts, &c.\n",
    "\n",
    "_Note: these functions can take quite a long time to complete._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    'purchase_amount': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'installments': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'month_lag': ['mean', 'min', 'max'],\n",
    "    'merchant_id': ['nunique'],\n",
    "    'state_id': ['nunique'],\n",
    "    'city_id': ['nunique'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the aggregators we only want to use for the `historical_transactions` data.\n",
    "hist_trans_aggs = {\n",
    "    'merchant_category_id': ['nunique'],\n",
    "    'subsector_id': ['nunique'],\n",
    "    'elapsed_since_last_purchase': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'elapsed_since_last_merch_purchase': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(train_and_validation_df, hist_trans_df, aggregators={**aggs, **hist_trans_aggs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical fields, we can't aggregate by taking the mean or sum values, so let's count the occurences of each possible categorical value instead. _(Iow, for a category that can be either YES or NO, we count the number of YESes and the number of NOs and use those values.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_categorical_fields(train_and_validation_df,\n",
    "                                  hist_trans_df,\n",
    "                                  column_names=['authorized_flag', 'category_1', 'category_2', 'category_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_top_categories(train_and_validation_df,\n",
    "                   hist_trans_df,\n",
    "                   column_names=['authorized_flag', 'category_1', 'subsector_id', 'city_id', 'state_id',\n",
    "                                 'purchase_Year', 'purchase_Month', 'purchase_Week', 'purchase_Day',\n",
    "                                 'purchase_Dayofweek'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Merchant Transactions\n",
    "\n",
    "Now lets do the same aggregating for the `new_merchants_transactions` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_trans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the aggregators we only want to use for the `new_merchants_transactions` data.\n",
    "merch_trans_aggs = {\n",
    "    'category_1_transaction': ['nunique'],\n",
    "    'category_2': ['nunique'],\n",
    "    'category_3': ['nunique'],\n",
    "    'category_4': ['nunique'],\n",
    "    'merchant_category_id_transaction': ['nunique'],\n",
    "    'merchant_category_id_merchant': ['nunique'],\n",
    "    'merchant_group_id': ['nunique'],\n",
    "    'subsector_id_merchant': ['nunique'],\n",
    "    'category_1_merchant': ['nunique'],\n",
    "    'state_id': ['nunique'],\n",
    "    'elapsed_since_last_purchase': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'numerical_1': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'numerical_2': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_sales_lag3': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_purchases_lag3': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'active_months_lag3': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_sales_lag6': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_purchases_lag6': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'active_months_lag6': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_sales_lag12': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'avg_purchases_lag12': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'active_months_lag12': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(train_and_validation_df, merch_trans_df, aggregators={**aggs, **merch_trans_aggs},\n",
    "                                prefix='merch_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason this fails for the `merch_trans_df` data frame, so let's skip these for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_aggregated_categorical_fields(train_and_validation_df,\n",
    "#                                  merch_trans_df,\n",
    "#                                  column_names=['category_1_transaction', 'merchant_category_id_transaction',\n",
    "#                                                'state_id', 'purchase_Year', 'month_lag'],\n",
    "#                                  prefix='merch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_top_categories(train_and_validation_df,\n",
    "#                   merch_trans_df,\n",
    "#                   column_names=['category_1_transaction', 'merchant_category_id_transaction',\n",
    "#                                 'state_id', 'purchase_Year', 'month_lag'],\n",
    "#                   prefix='merch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Test Set\n",
    "\n",
    "This takes a long time, too, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(test_df, hist_trans_df, aggregators={**aggs, **hist_trans_aggs})\n",
    "add_aggregated_categorical_fields(test_df,\n",
    "                                  hist_trans_df,\n",
    "                                  column_names=['authorized_flag', 'category_1', 'category_2', 'category_3'])\n",
    "add_top_categories(test_df,\n",
    "                   hist_trans_df,\n",
    "                   column_names=['authorized_flag', 'category_1', 'subsector_id', 'city_id', 'state_id',\n",
    "                                 'purchase_Year', 'purchase_Month', 'purchase_Week', 'purchase_Day',\n",
    "                                 'purchase_Dayofweek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(test_df, merch_trans_df, aggregators={**aggs, **merch_trans_aggs},\n",
    "                                prefix='merch_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Into Train and Validation Sets\n",
    "\n",
    "Split our data into a train test (80%) and a validation set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(train_and_validation_df, test_size=0.2, random_state=238923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "We shouldn't actually ever do this manually, except for experimental purposes. Spoiler: the outliers have a large impact on the final performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df[train_df.target > -25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Look at Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr().target.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model\n",
    "\n",
    "We'll use the fastai tabular regressor here, which is built for exactly this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Bunch\n",
    "\n",
    "A fastai DataBunch more or less contains the data that we'll feed to our model.\n",
    "\n",
    "First, as the data bunch takes one data frame containing both the test and validation samples, we need to get the indices for our validation samples.\n",
    "\n",
    "Then we tell the model which of the columns are categorical features, which are continuous features, and also which of the columns contains the target (the value we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = range(len(train_df), len(train_df) + len(validate_df)); valid_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at which columns we have. We will need to tell fastai which ones are categorical and which ones are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train_df.columns: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['feature_1',\n",
    "                  'feature_2',\n",
    "                  'feature_3',\n",
    "                  'authorized_flag_top',\n",
    "                  'category_1_top',\n",
    "                  'subsector_id_top',\n",
    "                  'city_id_top',\n",
    "                  'state_id_top',\n",
    "                  'purchase_Year_top',\n",
    "                  'purchase_Month_top',\n",
    "                  'purchase_Week_top',\n",
    "                  'purchase_Day_top',\n",
    "                  'purchase_Dayofweek_top']\n",
    "continuous_names = ['first_active_monthYear',\n",
    "                    'first_active_monthMonth',\n",
    "                    'first_active_monthWeek',\n",
    "                    'first_active_monthIs_quarter_start',\n",
    "                    'first_active_monthIs_year_start',\n",
    "                    'first_active_monthElapsed',\n",
    "                    'purchase_amount_sum',\n",
    "                    'purchase_amount_mean',\n",
    "                    'purchase_amount_min',\n",
    "                    'purchase_amount_max',\n",
    "                    'purchase_amount_std',\n",
    "                    'installments_sum',\n",
    "                    'installments_mean',\n",
    "                    'installments_min',\n",
    "                    'installments_max',\n",
    "                    'installments_std',\n",
    "                    'month_lag_mean',\n",
    "                    'month_lag_min',\n",
    "                    'month_lag_max',\n",
    "                    'merchant_id_nunique',\n",
    "                    'state_id_nunique',\n",
    "                    'city_id_nunique',\n",
    "                    'merchant_category_id_nunique',\n",
    "                    'subsector_id_nunique',\n",
    "                    'elapsed_since_last_purchase_sum',\n",
    "                    'elapsed_since_last_purchase_mean',\n",
    "                    'elapsed_since_last_purchase_min',\n",
    "                    'elapsed_since_last_purchase_max',\n",
    "                    'elapsed_since_last_purchase_std',\n",
    "                    'elapsed_since_last_merch_purchase_sum',\n",
    "                    'elapsed_since_last_merch_purchase_mean',\n",
    "                    'elapsed_since_last_merch_purchase_min',\n",
    "                    'elapsed_since_last_merch_purchase_max',\n",
    "                    'elapsed_since_last_merch_purchase_std',\n",
    "                    'authorized_flag_Y_ratio',\n",
    "                    'category_1_N_ratio',\n",
    "                    'category_2_1.0_ratio',\n",
    "                    'category_2_3.0_ratio',\n",
    "                    'category_2_4.0_ratio',\n",
    "                    'category_2_2.0_ratio',\n",
    "                    'category_2_5.0_ratio',\n",
    "                    'category_3_A_ratio',\n",
    "                    'category_3_B_ratio',\n",
    "                    'category_3_C_ratio',\n",
    "                    'merch_purchase_amount_sum',\n",
    "                    'merch_purchase_amount_mean',\n",
    "                    'merch_purchase_amount_min',\n",
    "                    'merch_purchase_amount_max',\n",
    "                    'merch_purchase_amount_std',\n",
    "                    'merch_installments_sum',\n",
    "                    'merch_installments_mean',\n",
    "                    'merch_installments_min',\n",
    "                    'merch_installments_max',\n",
    "                    'merch_installments_std',\n",
    "                    'merch_month_lag_mean',\n",
    "                    'merch_month_lag_min',\n",
    "                    'merch_month_lag_max',\n",
    "                    'merch_merchant_id_nunique',\n",
    "                    'merch_state_id_nunique',\n",
    "                    'merch_city_id_nunique',\n",
    "                    'merch_category_1_transaction_nunique',\n",
    "                    'merch_category_2_nunique',\n",
    "                    'merch_category_3_nunique',\n",
    "                    'merch_category_4_nunique',\n",
    "                    'merch_merchant_category_id_transaction_nunique',\n",
    "                    'merch_merchant_category_id_merchant_nunique',\n",
    "                    'merch_merchant_group_id_nunique',\n",
    "                    'merch_subsector_id_merchant_nunique',\n",
    "                    'merch_category_1_merchant_nunique',\n",
    "                    'merch_elapsed_since_last_purchase_sum',\n",
    "                    'merch_elapsed_since_last_purchase_mean',\n",
    "                    'merch_elapsed_since_last_purchase_min',\n",
    "                    'merch_elapsed_since_last_purchase_max',\n",
    "                    'merch_elapsed_since_last_purchase_std',\n",
    "                    'merch_numerical_1_sum',\n",
    "                    'merch_numerical_1_mean',\n",
    "                    'merch_numerical_1_min',\n",
    "                    'merch_numerical_1_max',\n",
    "                    'merch_numerical_1_std',\n",
    "                    'merch_numerical_2_sum',\n",
    "                    'merch_numerical_2_mean',\n",
    "                    'merch_numerical_2_min',\n",
    "                    'merch_numerical_2_max',\n",
    "                    'merch_numerical_2_std',\n",
    "                    'merch_avg_sales_lag3_sum',\n",
    "                    'merch_avg_sales_lag3_mean',\n",
    "                    'merch_avg_sales_lag3_min',\n",
    "                    'merch_avg_sales_lag3_max',\n",
    "                    'merch_avg_sales_lag3_std',\n",
    "                    'merch_avg_purchases_lag3_sum',\n",
    "                    'merch_avg_purchases_lag3_mean',\n",
    "                    'merch_avg_purchases_lag3_min',\n",
    "                    'merch_avg_purchases_lag3_max',\n",
    "                    'merch_avg_purchases_lag3_std',\n",
    "                    'merch_active_months_lag3_sum',\n",
    "                    'merch_active_months_lag3_mean',\n",
    "                    'merch_active_months_lag3_min',\n",
    "                    'merch_active_months_lag3_max',\n",
    "                    'merch_active_months_lag3_std',\n",
    "                    'merch_avg_sales_lag6_sum',\n",
    "                    'merch_avg_sales_lag6_mean',\n",
    "                    'merch_avg_sales_lag6_min',\n",
    "                    'merch_avg_sales_lag6_max',\n",
    "                    'merch_avg_sales_lag6_std',\n",
    "                    'merch_avg_purchases_lag6_sum',\n",
    "                    'merch_avg_purchases_lag6_mean',\n",
    "                    'merch_avg_purchases_lag6_min',\n",
    "                    'merch_avg_purchases_lag6_max',\n",
    "                    'merch_avg_purchases_lag6_std',\n",
    "                    'merch_active_months_lag6_sum',\n",
    "                    'merch_active_months_lag6_mean',\n",
    "                    'merch_active_months_lag6_min',\n",
    "                    'merch_active_months_lag6_max',\n",
    "                    'merch_active_months_lag6_std',\n",
    "                    'merch_avg_sales_lag12_sum',\n",
    "                    'merch_avg_sales_lag12_mean',\n",
    "                    'merch_avg_sales_lag12_min',\n",
    "                    'merch_avg_sales_lag12_max',\n",
    "                    'merch_avg_sales_lag12_std',\n",
    "                    'merch_avg_purchases_lag12_sum',\n",
    "                    'merch_avg_purchases_lag12_mean',\n",
    "                    'merch_avg_purchases_lag12_min',\n",
    "                    'merch_avg_purchases_lag12_max',\n",
    "                    'merch_avg_purchases_lag12_std',\n",
    "                    'merch_active_months_lag12_sum',\n",
    "                    'merch_active_months_lag12_mean',\n",
    "                    'merch_active_months_lag12_min',\n",
    "                    'merch_active_months_lag12_max',\n",
    "                    'merch_active_months_lag12_std',]\n",
    "dep_var = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we picked our validation samples randomly from the initial data set, and since fastai requires us to give the indices of the validation samples in a data frame containing both the training and validation samples, we just concatenate them together with training samples first and the validation samples at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, validate_df]).reset_index()[category_names + continuous_names + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df,\n",
    "                            path='data/unzipped',\n",
    "                            cat_names=category_names,\n",
    "                            cont_names=continuous_names,\n",
    "                            procs=[FillMissing, Categorify, Normalize])\n",
    "                .split_by_idx(valid_idx)\n",
    "                .label_from_df(cols=dep_var, label_cls=FloatList)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a random batch of data to see how it looks after the processing done by the fastai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Learner\n",
    "\n",
    "This is what we actually use to train the model and make predictions.\n",
    "\n",
    "First we decide how large we want to make the embeddings of our categorical features (the number of category options divided by 2 is a good heuristic, apparently).\n",
    "\n",
    "Then we tell the model the range within which we expect all predictions to fall (internally the model uses a sigmoid function, so in order for us, in practice, to actually get predictions near the expected maximum value, we set the upper bound to be a little higher than the expected maximum).\n",
    "\n",
    "The competition uses root mean squared error to evaluate the entries, so we'll use that, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = np.min(train_df['target']) * 1.2\n",
    "max_y = np.max(train_df['target']) * 1.2\n",
    "y_range = torch.tensor([min_y, max_y], device=defaults.device); y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_df['target']), np.max(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data,\n",
    "                        layers=[400, 200],\n",
    "                        ps=[2e-1, 1e-1],\n",
    "                        emb_drop=0.04,\n",
    "                        y_range=y_range,\n",
    "                        metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Out Learning Rate\n",
    "\n",
    "To figure out which learning rate to use, we use fastai's learning rate finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "Finally we train the model, with weight decay to encourage the model to use fewer features, and then show some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 1e-3, wd=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Now that we have trained our model, lets make some predictions to see whether or not our metrics lie to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = [x.numpy().flatten() for x in learn.get_preds(DatasetType.Valid)]\n",
    "prediction_df = pd.DataFrame({'prediction': predictions, 'target': targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.amin(predictions), np.amax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE On Validation Set\n",
    "\n",
    "Get the root mean squared error for the validation set only. This value we can compare against the public leaderboard on Kaggle, more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean_squared_error(prediction_df.target, prediction_df.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission Predictions\n",
    "\n",
    "Finally, we need to run our model against the test set that is used by the competition's organizers to evaluate the competitors. We save the result to a `submission.csv` file which we'll then upload to Kaggle.\n",
    "\n",
    "_Note: we should only do this at the very end, when we are happy with our hyperparameters. Otherwise, if we change our model based on our results on the public leaderboard, we risk overfitting our model to the 30% of samples used for the public leaderboard, and will fail to generalize for the remaining 70% of samples._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = test_df.copy(); out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set has one row with some missing values (which we don't have in the training set), so let's use the most commonly occuring ones for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.fillna(value={'first_active_monthYear': '2017.0',\n",
    "                     'first_active_monthMonth': '12.0',\n",
    "                     'first_active_monthWeek': '44.0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning -- this takes quite a long time.\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "targets = []\n",
    "for _, row in tqdm(out_df.iterrows()):\n",
    "    targets.append(learn.predict(row)[2].numpy().flatten()[0])\n",
    "out_df['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['target'].to_csv('submission.csv.zip', header=['target'], index_label='card_id', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
