{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to Predict Elo Customer Loyalty\n",
    "\n",
    "_Note! If you want to commit any changes to this document, please strip all output (Cell > Current Outputs > Clear, or set up [nbstripout](https://github.com/kynan/nbstripout) as a git filter) from this notebook before doing so. Thanks!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Next we import the Python libraries we'll need. If any of these are missing for you, you can install them with e.g. `pip3 install pandas` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the data into Pandas data frames and look at their structure.\n",
    "\n",
    "First thing we'll do with the training data is split it into a train and validation set. (The given test set is what we'll later make our predictions on and upload, but only after we are fully satisfied with our model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df = pd.read_csv('data/unzipped/historical_transactions.csv',\n",
    "                            parse_dates=['purchase_date'])\n",
    "merchants_df = pd.read_csv('data/unzipped/merchants.csv',\n",
    "                           index_col='merchant_id')\n",
    "merch_trans_df = pd.read_csv('data/unzipped/new_merchant_transactions.csv',\n",
    "                             parse_dates=['purchase_date'])\n",
    "train_and_validation_df = pd.read_csv('data/unzipped/train.csv',\n",
    "                                      index_col='card_id',\n",
    "                                      parse_dates=['first_active_month'])\n",
    "test_df = pd.read_csv('data/unzipped/test.csv',\n",
    "                      index_col='card_id',\n",
    "                      parse_dates=['first_active_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['feature_1', 'feature_2', 'feature_3']:\n",
    "    train_and_validation_df[v] = train_and_validation_df[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['authorized_flag', 'category_1', 'category_2', 'category_3', 'merchant_id', 'merchant_category_id',\n",
    "          'subsector_id', 'city_id', 'state_id']:\n",
    "    hist_trans_df[v] = hist_trans_df[v].astype('category').cat.as_ordered()\n",
    "    merch_trans_df[v] = merch_trans_df[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features\n",
    "\n",
    "Next we want to combine and shape all of our raw data to create useful features in the train (and validation and test) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.metrics import *\n",
    "from feature_engineering import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai has a useful helper function called `add_datepart()`, which takes a date field and turns it into a bunch of useful columns, such as \"day of week\", \"is month end\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(hist_trans_df, 'purchase_date')\n",
    "add_datepart(merch_trans_df, 'purchase_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also calculate, for each purchase, the time passed since _the last purchase for that card and merchant combination_, e.g. for a transaction of me buying toilet paper at Rewe (true story, by the way), it would be the time passed since I last bought anything at Rewe, or `nan` had I never bought anything there.\n",
    "\n",
    "We don't do this for the new merchant transactions, because there there's only ever one purchase for each card-merchant combination, so this value would always be `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.sort_values(by=['purchase_Elapsed'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `merchant_id` can be nan, we need to treat those as non-nan temporarily in order not to drop rows when grouping. We also filter the data frame, since we are only interested in these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = hist_trans_df[['card_id', 'merchant_id', 'purchase_Elapsed']]\n",
    "filtered['merchant_id'] = filtered['merchant_id'].cat.add_categories('temp_nan').fillna('temp_nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = filtered.groupby(['card_id', 'merchant_id'], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate by getting the `diff` (i.e. the value at `n` minus the value at `n - 1`).\n",
    "\n",
    "_**Warning!** This takes a very long time ..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df['elapsed_since_merchant_purchase'] = grouped.agg({'purchase_Elapsed': 'diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Transaction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the functions defined in `feature_engineering.py` to aggregate the historical transactions for each card into single values for that card, for instance the mean of all purchase amounts, &c.\n",
    "\n",
    "_Note: these functions can take quite a long time to complete._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregators = {\n",
    "    'purchase_amount': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'installments': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "    'month_lag': ['mean', 'min', 'max'],\n",
    "    'merchant_id': ['nunique'],\n",
    "    'merchant_category_id': ['nunique'],\n",
    "    'state_id': ['nunique'],\n",
    "    'city_id': ['nunique'],\n",
    "    'subsector_id': ['nunique'],\n",
    "    'elapsed_since_merchant_purchase': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(train_and_validation_df, hist_trans_df, aggregators=aggregators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical fields, we can't aggregate by taking the mean or sum values, so let's count the occurences of each possible categorical value instead. _(Iow, for a category that can be either YES or NO, we count the number of YESes and the number of NOs and use those values.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_categorical_fields(train_and_validation_df,\n",
    "                                  hist_trans_df,\n",
    "                                  column_names=['authorized_flag', 'category_1', 'category_2', 'category_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_2 and category_3 contain nan values, so let's skip those for now.\n",
    "add_top_categories(train_and_validation_df,\n",
    "                   hist_trans_df,\n",
    "                   column_names=['authorized_flag', 'category_1', 'subsector_id', 'city_id', 'state_id',\n",
    "                                 'purchase_Year', 'purchase_Month', 'purchase_Week', 'purchase_Day',\n",
    "                                 'purchase_Dayofweek'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do the same aggregating for the `new_merchants_transactions` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(train_and_validation_df, merch_trans_df, aggregators=aggregators, prefix='merch_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table concerns only authorized transactions, so we don't need to include that column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_categorical_fields(train_and_validation_df,\n",
    "                                  merch_trans_df,\n",
    "                                  column_names=['category_1', 'category_2', 'category_3'],\n",
    "                                  prefix='merch_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`category_2` and `category_3` contain nan values, so let's skip those for now.\n",
    "\n",
    "For some reason this fails for the `merch_trans_df` data frame, so let's skip these for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_top_categories(train_and_validation_df,\n",
    "#                   merch_trans_df,\n",
    "#                   column_names=['category_1', 'subsector_id', 'city_id', 'state_id'],\n",
    "#                   prefix='merch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_aggregated_numerical_fields(test_df, hist_trans_df, aggregators=aggregators)\n",
    "add_aggregated_categorical_fields(test_df,\n",
    "                                  hist_trans_df,\n",
    "                                  column_names=['authorized_flag', 'category_1', 'category_2', 'category_3'])\n",
    "# category_2 and category_3 contain nan values, so let's skip those for now.\n",
    "add_top_categories(test_df,\n",
    "                   hist_trans_df,\n",
    "                   column_names=['authorized_flag', 'category_1', 'subsector_id', 'city_id', 'state_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Into Train and Validation Sets\n",
    "\n",
    "Split our data into a train test (80%) and a validation set (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(train_and_validation_df, test_size=0.2, random_state=238923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "We shouldn't actually ever do this manually, except for experimental purposes. Spoiler: the outliers have a large impact on the final performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df[train_df.target > -25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Look at Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr().target.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model\n",
    "\n",
    "We'll use the fastai tabular regressor here, which is built for exactly this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Bunch\n",
    "\n",
    "A fastai DataBunch more or less contains the data that we'll feed to our model.\n",
    "\n",
    "First, as the data bunch takes one data frame containing both the test and validation samples, we need to get the indices for our validation samples.\n",
    "\n",
    "Then we tell the model which of the columns are categorical features, which are continuous features, and also which of the columns contains the target (the value we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = range(len(train_df), len(train_df) + len(validate_df)); valid_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at which columns we have. We will need to tell fastai which ones are categorical and which ones are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['feature_1',\n",
    "                  'feature_2',\n",
    "                  'feature_3',\n",
    "                  'authorized_flag_top',\n",
    "                  'category_1_top',\n",
    "                  'subsector_id_top',\n",
    "                  'city_id_top',\n",
    "                  'state_id_top',\n",
    "                  'purchase_Year_top',\n",
    "                  'purchase_Month_top',\n",
    "                  'purchase_Week_top',\n",
    "                  'purchase_Day_top',\n",
    "                  'purchase_Dayofweek_top']\n",
    "continuous_names = ['purchase_amount_sum',\n",
    "                    'purchase_amount_mean',\n",
    "                    'purchase_amount_min',\n",
    "                    'purchase_amount_max',\n",
    "                    'purchase_amount_std',\n",
    "                    'installments_sum',\n",
    "                    'installments_mean',\n",
    "                    'installments_min',\n",
    "                    'installments_max',\n",
    "                    'installments_std',\n",
    "                    'month_lag_mean',\n",
    "                    'month_lag_min',\n",
    "                    'month_lag_max',\n",
    "                    'merchant_id_nunique',\n",
    "                    'merchant_category_id_nunique',\n",
    "                    'state_id_nunique',\n",
    "                    'city_id_nunique',\n",
    "                    'subsector_id_nunique',\n",
    "                    'elapsed_since_merchant_purchase_sum',\n",
    "                    'elapsed_since_merchant_purchase_mean',\n",
    "                    'elapsed_since_merchant_purchase_min',\n",
    "                    'elapsed_since_merchant_purchase_max',\n",
    "                    'elapsed_since_merchant_purchase_std',\n",
    "                    'authorized_flag_Y_ratio',\n",
    "                    'category_1_Y_ratio',\n",
    "                    'category_2_1.0_ratio',\n",
    "                    'category_2_2.0_ratio',\n",
    "                    'category_2_3.0_ratio',\n",
    "                    'category_2_4.0_ratio',\n",
    "                    'category_2_5.0_ratio',\n",
    "                    'category_3_A_ratio',\n",
    "                    'category_3_B_ratio',\n",
    "                    'category_3_C_ratio',\n",
    "                    'merch_purchase_amount_sum',\n",
    "                    'merch_purchase_amount_mean',\n",
    "                    'merch_purchase_amount_min',\n",
    "                    'merch_purchase_amount_max',\n",
    "                    'merch_purchase_amount_std',\n",
    "                    'merch_installments_sum',\n",
    "                    'merch_installments_mean',\n",
    "                    'merch_installments_min',\n",
    "                    'merch_installments_max',\n",
    "                    'merch_installments_std',\n",
    "                    'merch_month_lag_mean',\n",
    "                    'merch_month_lag_min',\n",
    "                    'merch_month_lag_max',\n",
    "                    'merch_merchant_id_nunique',\n",
    "                    'merch_merchant_category_id_nunique',\n",
    "                    'merch_state_id_nunique',\n",
    "                    'merch_city_id_nunique',\n",
    "                    'merch_subsector_id_nunique',\n",
    "                    'merch_category_1_Y_ratio',\n",
    "                    'merch_category_2_1.0_ratio',\n",
    "                    'merch_category_2_3.0_ratio',\n",
    "                    'merch_category_2_2.0_ratio',\n",
    "                    'merch_category_2_4.0_ratio',\n",
    "                    'merch_category_2_5.0_ratio',\n",
    "                    'merch_category_3_A_ratio',\n",
    "                    'merch_category_3_B_ratio',\n",
    "                    'merch_category_3_C_ratio']\n",
    "dep_var = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we picked our validation samples randomly from the initial data set, and since fastai requires us to give the indices of the validation samples in a data frame containing both the training and validation samples, we just concatenate them together with training samples first and the validation samples at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, validate_df]).reset_index()[category_names + continuous_names + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df,\n",
    "                            path='data/unzipped',\n",
    "                            cat_names=category_names,\n",
    "                            cont_names=continuous_names,\n",
    "                            procs=[FillMissing, Categorify, Normalize])\n",
    "                .split_by_idx(valid_idx)\n",
    "                .label_from_df(cols=dep_var, label_cls=FloatList)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a random batch of data to see how it looks after the processing done by the fastai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Learner\n",
    "\n",
    "This is what we actually use to train the model and make predictions.\n",
    "\n",
    "First we decide how large we want to make the embeddings of our categorical features (the number of category options divided by 2 is a good heuristic, apparently).\n",
    "\n",
    "Then we tell the model the range within which we expect all predictions to fall (internally the model uses a sigmoid function, so in order for us, in practice, to actually get predictions near the expected maximum value, we set the upper bound to be a little higher than the expected maximum).\n",
    "\n",
    "The competition uses root mean squared error to evaluate the entries, so we'll use that, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = np.min(train_df['target']) * 1.2\n",
    "max_y = np.max(train_df['target']) * 1.2\n",
    "y_range = torch.tensor([min_y, max_y], device=defaults.device); y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_df['target']), np.max(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data,\n",
    "                        layers=[200, 100],\n",
    "                        ps=[1e-2, 1e-1],\n",
    "                        emb_drop=0.04,\n",
    "                        y_range=y_range,\n",
    "                        metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Out Learning Rate\n",
    "\n",
    "To figure out which learning rate to use, we use fastai's learning rate finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "Finally we train the model, with weight decay to encourage the model to use fewer features, and then show some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-3, wd=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Now that we have trained our model, lets make some predictions to see whether or not our metrics lie to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = [x.numpy().flatten() for x in learn.get_preds(DatasetType.Valid)]\n",
    "prediction_df = pd.DataFrame({'prediction': predictions, 'target': targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.amin(predictions), np.amax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE On Validation Set\n",
    "\n",
    "Get the root mean squared error for the validation set only. This value we can compare against the public leaderboard on Kaggle, more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean_squared_error(prediction_df.target, prediction_df.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission Predictions\n",
    "\n",
    "Finally, we need to run our model against the test set that is used by the competition's organizers to evaluate the competitors. We save the result to a `submission.csv` file which we'll then upload to Kaggle.\n",
    "\n",
    "_Note: we should only do this at the very end, when we are happy with our hyperparameters. Otherwise, if we change our model based on our results on the public leaderboard, we risk overfitting our model to the 30% of samples used for the public leaderboard, and will fail to generalize for the remaining 70% of samples._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = test_df.copy(); out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning -- this takes quite a long time.\n",
    "out_df['target'] = [learn.predict(row)[2].numpy().flatten()[0] for _, row in out_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['target'].to_csv('submission.csv.zip', header=['target'], index_label='card_id', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
