{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to Predict Elo Customer Loyalty\n",
    "\n",
    "_Note! If you want to commit any changes to this document, please strip all output (Cell > Current Outputs > Clear, or set up [nbstripout](https://github.com/kynan/nbstripout) as a git filter) from this notebook before doing so. Thanks!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Next we import the Python libraries we'll need. If any of these are missing for you, you can install them with e.g. `pip3 install pandas` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the data into Pandas data frames and look at their structure.\n",
    "\n",
    "First thing we'll do with the training data is split it into a train and validation set. (The given test set is what we'll later make our predictions on and upload, but only after we are fully satisfied with our model.)\n",
    "\n",
    "**Make sure to run `make processdata` (which takes a very long time, but only needs to be done once) before running the code in this notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df = pd.read_csv('data/processed/train_with_aggregated_features.csv', index_col='card_id')\n",
    "test_df = pd.read_csv('data/processed/test_with_aggregated_features.csv', index_col='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Into Train and Validation Sets\n",
    "\n",
    "Split our data into a train test (80%) and a validation set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(train_and_validation_df, test_size=0.2, random_state=238923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "We shouldn't actually ever do this manually, except for experimental purposes. Spoiler: the outliers have a large impact on the final performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df[train_df.target > -25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Look at Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr().target.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model\n",
    "\n",
    "We'll use the fastai tabular regressor here, which is built for exactly this sort of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Bunch\n",
    "\n",
    "A fastai DataBunch more or less contains the data that we'll feed to our model.\n",
    "\n",
    "First, as the data bunch takes one data frame containing both the test and validation samples, we need to get the indices for our validation samples.\n",
    "\n",
    "Then we tell the model which of the columns are categorical features, which are continuous features, and also which of the columns contains the target (the value we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = range(len(train_df), len(train_df) + len(validate_df)); valid_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at which columns we have. We will need to tell fastai which ones are categorical and which ones are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train_df.columns: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['first_active_monthYear',\n",
    "                  'first_active_monthMonth',\n",
    "                  'first_active_monthWeek',\n",
    "                  'first_active_monthIs_quarter_start',\n",
    "                  'first_active_monthIs_year_start',\n",
    "                  'feature_1',\n",
    "                  'feature_2',\n",
    "                  'feature_3',\n",
    "                  'authorized_flag_top',\n",
    "                  'category_1_transaction_top',\n",
    "                  'category_1_merchant_top',\n",
    "                  'category_2_top',\n",
    "                  'category_3_top',\n",
    "                  'category_4_top',\n",
    "                  'subsector_id_transaction_top',\n",
    "                  'subsector_id_merchant_top',\n",
    "                  'city_id_top',\n",
    "                  'state_id_top',\n",
    "                  'purchase_Year_top',\n",
    "                  'purchase_Month_top',\n",
    "                  'purchase_Week_top',\n",
    "                  'purchase_Day_top',\n",
    "                  'purchase_Dayofweek_top',\n",
    "                  'most_recent_sales_range_top',\n",
    "                  'most_recent_purchases_range_top',\n",
    "                  'merch_authorized_flag_top',\n",
    "                  'merch_category_1_transaction_top',\n",
    "                  'merch_category_1_merchant_top',\n",
    "                  'merch_category_2_top',\n",
    "                  'merch_category_3_top',\n",
    "                  'merch_category_4_top',\n",
    "                  'merch_subsector_id_transaction_top',\n",
    "                  'merch_subsector_id_merchant_top',\n",
    "                  'merch_city_id_top',\n",
    "                  'merch_state_id_top',\n",
    "                  'merch_purchase_Year_top',\n",
    "                  'merch_purchase_Month_top',\n",
    "                  'merch_purchase_Week_top',\n",
    "                  'merch_purchase_Day_top',\n",
    "                  'merch_purchase_Dayofweek_top',\n",
    "                  'merch_most_recent_sales_range_top',\n",
    "                  'merch_most_recent_purchases_range_top',]\n",
    "continuous_names = ['first_active_monthElapsed',\n",
    "                    'purchase_amount_sum',\n",
    "                    'purchase_amount_mean',\n",
    "                    'purchase_amount_min',\n",
    "                    'purchase_amount_max',\n",
    "                    'purchase_amount_std',\n",
    "                    'installments_sum',\n",
    "                    'installments_mean',\n",
    "                    'installments_min',\n",
    "                    'installments_max',\n",
    "                    'installments_std',\n",
    "                    'month_lag_mean',\n",
    "                    'month_lag_min',\n",
    "                    'month_lag_max',\n",
    "                    'merchant_id_nunique',\n",
    "                    'state_id_nunique',\n",
    "                    'city_id_nunique',\n",
    "                    'numerical_1_sum',\n",
    "                    'numerical_1_mean',\n",
    "                    'numerical_1_min',\n",
    "                    'numerical_1_max',\n",
    "                    'numerical_1_std',\n",
    "                    'numerical_2_sum',\n",
    "                    'numerical_2_mean',\n",
    "                    'numerical_2_min',\n",
    "                    'numerical_2_max',\n",
    "                    'numerical_2_std',\n",
    "                    'avg_sales_lag3_sum',\n",
    "                    'avg_sales_lag3_mean',\n",
    "                    'avg_sales_lag3_min',\n",
    "                    'avg_sales_lag3_max',\n",
    "                    'avg_sales_lag3_std',\n",
    "                    'avg_sales_lag6_sum',\n",
    "                    'avg_sales_lag6_mean',\n",
    "                    'avg_sales_lag6_min',\n",
    "                    'avg_sales_lag6_max',\n",
    "                    'avg_sales_lag6_std',\n",
    "                    'avg_sales_lag12_sum',\n",
    "                    'avg_sales_lag12_mean',\n",
    "                    'avg_sales_lag12_min',\n",
    "                    'avg_sales_lag12_max',\n",
    "                    'avg_sales_lag12_std',\n",
    "                    'avg_purchases_lag3_sum',\n",
    "                    'avg_purchases_lag3_mean',\n",
    "                    'avg_purchases_lag3_min',\n",
    "                    'avg_purchases_lag3_max',\n",
    "                    'avg_purchases_lag3_std',\n",
    "                    'avg_purchases_lag6_sum',\n",
    "                    'avg_purchases_lag6_mean',\n",
    "                    'avg_purchases_lag6_min',\n",
    "                    'avg_purchases_lag6_max',\n",
    "                    'avg_purchases_lag6_std',\n",
    "                    'avg_purchases_lag12_sum',\n",
    "                    'avg_purchases_lag12_mean',\n",
    "                    'avg_purchases_lag12_min',\n",
    "                    'avg_purchases_lag12_max',\n",
    "                    'avg_purchases_lag12_std',\n",
    "                    'active_months_lag3_sum',\n",
    "                    'active_months_lag3_mean',\n",
    "                    'active_months_lag3_min',\n",
    "                    'active_months_lag3_std',\n",
    "                    'active_months_lag6_sum',\n",
    "                    'active_months_lag6_mean',\n",
    "                    'active_months_lag6_min',\n",
    "                    'active_months_lag6_std',\n",
    "                    'active_months_lag12_sum',\n",
    "                    'active_months_lag12_mean',\n",
    "                    'active_months_lag12_min',\n",
    "                    'active_months_lag12_max',\n",
    "                    'active_months_lag12_std',\n",
    "                    'merchant_category_id_transaction_nunique',\n",
    "                    'merchant_category_id_merchant_nunique',\n",
    "                    'subsector_id_transaction_nunique',\n",
    "                    'subsector_id_merchant_nunique',\n",
    "                    'merchant_group_id_nunique',\n",
    "                    'most_recent_sales_range_nunique',\n",
    "                    'most_recent_purchases_range_nunique',\n",
    "                    'elapsed_since_last_purchase_sum',\n",
    "                    'elapsed_since_last_purchase_mean',\n",
    "                    'elapsed_since_last_purchase_min',\n",
    "                    'elapsed_since_last_purchase_max',\n",
    "                    'elapsed_since_last_purchase_std',\n",
    "                    'elapsed_since_last_merch_purchase_sum',\n",
    "                    'elapsed_since_last_merch_purchase_mean',\n",
    "                    'elapsed_since_last_merch_purchase_min',\n",
    "                    'elapsed_since_last_merch_purchase_max',\n",
    "                    'elapsed_since_last_merch_purchase_std',\n",
    "                    'authorized_flag_Y_ratio',\n",
    "                    'category_1_transaction_N_ratio',\n",
    "                    'category_1_merchant_N_ratio',\n",
    "                    'category_2_1.0_ratio',\n",
    "                    'category_2_3.0_ratio',\n",
    "                    'category_2_4.0_ratio',\n",
    "                    'category_2_2.0_ratio',\n",
    "                    'category_2_5.0_ratio',\n",
    "                    'category_3_A_ratio',\n",
    "                    'category_3_B_ratio',\n",
    "                    'category_3_C_ratio',\n",
    "                    'category_4_N_ratio',\n",
    "                    'purchase_Is_month_start_True_ratio',\n",
    "                    'purchase_Is_month_end_False_ratio',\n",
    "                    'purchase_Year_2017_ratio',\n",
    "                    'most_recent_sales_range_B_ratio',\n",
    "                    'most_recent_sales_range_A_ratio',\n",
    "                    'most_recent_sales_range_C_ratio',\n",
    "                    'most_recent_sales_range_D_ratio',\n",
    "                    'most_recent_sales_range_E_ratio',\n",
    "                    'most_recent_purchases_range_B_ratio',\n",
    "                    'most_recent_purchases_range_C_ratio',\n",
    "                    'most_recent_purchases_range_A_ratio',\n",
    "                    'most_recent_purchases_range_D_ratio',\n",
    "                    'most_recent_purchases_range_E_ratio',\n",
    "                    'merch_purchase_amount_sum',\n",
    "                    'merch_purchase_amount_mean',\n",
    "                    'merch_purchase_amount_min',\n",
    "                    'merch_purchase_amount_max',\n",
    "                    'merch_purchase_amount_std',\n",
    "                    'merch_installments_sum',\n",
    "                    'merch_installments_mean',\n",
    "                    'merch_installments_min',\n",
    "                    'merch_installments_max',\n",
    "                    'merch_installments_std',\n",
    "                    'merch_month_lag_mean',\n",
    "                    'merch_month_lag_min',\n",
    "                    'merch_month_lag_max',\n",
    "                    'merch_merchant_id_nunique',\n",
    "                    'merch_state_id_nunique',\n",
    "                    'merch_city_id_nunique',\n",
    "                    'merch_numerical_1_sum',\n",
    "                    'merch_numerical_1_mean',\n",
    "                    'merch_numerical_1_min',\n",
    "                    'merch_numerical_1_max',\n",
    "                    'merch_numerical_1_std',\n",
    "                    'merch_numerical_2_sum',\n",
    "                    'merch_numerical_2_mean',\n",
    "                    'merch_numerical_2_min',\n",
    "                    'merch_numerical_2_max',\n",
    "                    'merch_numerical_2_std',\n",
    "                    'merch_avg_sales_lag3_sum',\n",
    "                    'merch_avg_sales_lag3_mean',\n",
    "                    'merch_avg_sales_lag3_min',\n",
    "                    'merch_avg_sales_lag3_max',\n",
    "                    'merch_avg_sales_lag3_std',\n",
    "                    'merch_avg_sales_lag6_sum',\n",
    "                    'merch_avg_sales_lag6_mean',\n",
    "                    'merch_avg_sales_lag6_min',\n",
    "                    'merch_avg_sales_lag6_max',\n",
    "                    'merch_avg_sales_lag6_std',\n",
    "                    'merch_avg_sales_lag12_sum',\n",
    "                    'merch_avg_sales_lag12_mean',\n",
    "                    'merch_avg_sales_lag12_min',\n",
    "                    'merch_avg_sales_lag12_max',\n",
    "                    'merch_avg_sales_lag12_std',\n",
    "                    'merch_avg_purchases_lag3_sum',\n",
    "                    'merch_avg_purchases_lag3_mean',\n",
    "                    'merch_avg_purchases_lag3_min',\n",
    "                    'merch_avg_purchases_lag3_max',\n",
    "                    'merch_avg_purchases_lag3_std',\n",
    "                    'merch_avg_purchases_lag6_sum',\n",
    "                    'merch_avg_purchases_lag6_mean',\n",
    "                    'merch_avg_purchases_lag6_min',\n",
    "                    'merch_avg_purchases_lag6_max',\n",
    "                    'merch_avg_purchases_lag6_std',\n",
    "                    'merch_avg_purchases_lag12_sum',\n",
    "                    'merch_avg_purchases_lag12_mean',\n",
    "                    'merch_avg_purchases_lag12_min',\n",
    "                    'merch_avg_purchases_lag12_max',\n",
    "                    'merch_avg_purchases_lag12_std',\n",
    "                    'merch_active_months_lag3_sum',\n",
    "                    'merch_active_months_lag3_mean',\n",
    "                    'merch_active_months_lag3_min',\n",
    "                    'merch_active_months_lag3_max',\n",
    "                    'merch_active_months_lag3_std',\n",
    "                    'merch_active_months_lag6_sum',\n",
    "                    'merch_active_months_lag6_mean',\n",
    "                    'merch_active_months_lag6_min',\n",
    "                    'merch_active_months_lag6_max',\n",
    "                    'merch_active_months_lag6_std',\n",
    "                    'merch_active_months_lag12_sum',\n",
    "                    'merch_active_months_lag12_mean',\n",
    "                    'merch_active_months_lag12_min',\n",
    "                    'merch_active_months_lag12_max',\n",
    "                    'merch_active_months_lag12_std',\n",
    "                    'merch_merchant_category_id_transaction_nunique',\n",
    "                    'merch_merchant_category_id_merchant_nunique',\n",
    "                    'merch_subsector_id_transaction_nunique',\n",
    "                    'merch_subsector_id_merchant_nunique',\n",
    "                    'merch_merchant_group_id_nunique',\n",
    "                    'merch_most_recent_sales_range_nunique',\n",
    "                    'merch_most_recent_purchases_range_nunique',\n",
    "                    'merch_elapsed_since_last_purchase_sum',\n",
    "                    'merch_elapsed_since_last_purchase_mean',\n",
    "                    'merch_elapsed_since_last_purchase_min',\n",
    "                    'merch_elapsed_since_last_purchase_max',\n",
    "                    'merch_elapsed_since_last_purchase_std',\n",
    "                    'merch_category_1_transaction_N_ratio',\n",
    "                    'merch_category_1_merchant_N_ratio',\n",
    "                    'merch_category_2_1.0_ratio',\n",
    "                    'merch_category_2_4.0_ratio',\n",
    "                    'merch_category_2_2.0_ratio',\n",
    "                    'merch_category_2_3.0_ratio',\n",
    "                    'merch_category_2_5.0_ratio',\n",
    "                    'merch_category_3_B_ratio',\n",
    "                    'merch_category_3_A_ratio',\n",
    "                    'merch_category_3_C_ratio',\n",
    "                    'merch_category_4_Y_ratio',\n",
    "                    'merch_category_4_N_ratio',\n",
    "                    'merch_purchase_Is_month_start_True_ratio',\n",
    "                    'merch_purchase_Is_month_end_False_ratio',\n",
    "                    'merch_purchase_Year_2017_ratio',\n",
    "                    'merch_purchase_Year_2018_ratio',\n",
    "                    'merch_most_recent_sales_range_A_ratio',\n",
    "                    'merch_most_recent_sales_range_B_ratio',\n",
    "                    'merch_most_recent_sales_range_D_ratio',\n",
    "                    'merch_most_recent_sales_range_E_ratio',\n",
    "                    'merch_most_recent_sales_range_C_ratio',\n",
    "                    'merch_most_recent_purchases_range_A_ratio',\n",
    "                    'merch_most_recent_purchases_range_B_ratio',\n",
    "                    'merch_most_recent_purchases_range_D_ratio',\n",
    "                    'merch_most_recent_purchases_range_C_ratio',\n",
    "                    'merch_most_recent_purchases_range_E_ratio',]\n",
    "dep_var = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we picked our validation samples randomly from the initial data set, and since fastai requires us to give the indices of the validation samples in a data frame containing both the training and validation samples, we just concatenate them together with training samples first and the validation samples at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, validate_df]).reset_index()[category_names + continuous_names + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df,\n",
    "                            path='learner',\n",
    "                            cat_names=category_names,\n",
    "                            cont_names=continuous_names,\n",
    "                            procs=[FillMissing, Categorify, Normalize])\n",
    "                .split_by_idx(valid_idx)\n",
    "                .label_from_df(cols=dep_var, label_cls=FloatList)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a random batch of data to see how it looks after the processing done by the fastai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Learner\n",
    "\n",
    "This is what we actually use to train the model and make predictions.\n",
    "\n",
    "First we decide how large we want to make the embeddings of our categorical features (the number of category options divided by 2 is a good heuristic, apparently).\n",
    "\n",
    "Then we tell the model the range within which we expect all predictions to fall (internally the model uses a sigmoid function, so in order for us, in practice, to actually get predictions near the expected maximum value, we set the upper bound to be a little higher than the expected maximum).\n",
    "\n",
    "The competition uses root mean squared error to evaluate the entries, so we'll use that, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = np.min(train_df['target']) * 1.2\n",
    "max_y = np.max(train_df['target']) * 1.2\n",
    "y_range = torch.tensor([min_y, max_y], device=defaults.device); y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_df['target']), np.max(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data,\n",
    "                        layers=[400, 200],\n",
    "                        ps=[2e-1, 1e-1],\n",
    "                        emb_drop=0.04,\n",
    "                        y_range=y_range,\n",
    "                        metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load an already trained model (look into `learner/models/`) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('model_cv_3_908')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Out Learning Rate\n",
    "\n",
    "To figure out which learning rate to use, we use fastai's learning rate finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "Finally we train the model, with weight decay to encourage the model to use fewer features, and then show some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 1e-3, wd=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Now that we have trained our model, lets make some predictions to see whether or not our metrics lie to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = [x.numpy().flatten() for x in learn.get_preds(DatasetType.Valid)]\n",
    "prediction_df = pd.DataFrame({'prediction': predictions, 'target': targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.amin(predictions), np.amax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE On Validation Set\n",
    "\n",
    "Get the root mean squared error for the validation set only. This value we can compare against the public leaderboard on Kaggle, more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean_squared_error(prediction_df.target, prediction_df.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save The Model\n",
    "\n",
    "If the model performed well, save it here (adding the validation error to the name) so that we can load it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_cv_3_885')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Testing\n",
    "\n",
    "Hyperparameters are all those values that _we_ have to set to describe our model and how it learns (as opposed to the weights that are set _by the model_). For instance, we have to decide how many hidden layers it should have, and how many neurons there should be in each of those layers, etc.\n",
    "\n",
    "Instead of using heuristics and experiments to find the optimal values for these, as we normally would, we can use Bayesian optimization in order to find them. I based the implementation on that of [this article](https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a).\n",
    "\n",
    "**Feel free to skip this step!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, plotting\n",
    "import hyperopt.pyll.stochastic\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(params):\n",
    "    '''Given a hyperparameter dictionary, return a pair of lists, one containing \n",
    "    the layer sizes and one the dropouts for each layer.'''\n",
    "    layer_range = range(0, int(params['num_layers']))\n",
    "    layers = [round(params['layer_size'] / pow(2, i)) for i in layer_range]\n",
    "    ps = [params['layer_dropout'] / pow(10, i) for i in layer_range][::-1]\n",
    "    return layers, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    '''Given a set of parameters, train the model for some epochs and return\n",
    "    the lowest validation error found during those runs.'''\n",
    "    layers, ps = get_layers(params)\n",
    "    learn = tabular_learner(data,\n",
    "                            layers=layers,\n",
    "                            ps=ps,\n",
    "                            emb_drop=params['emb_drop'],\n",
    "                            y_range=y_range,\n",
    "                            metrics=rmse)\n",
    "\n",
    "    # Train for a set number of epochs.\n",
    "    learn.fit_one_cycle(5, params['lr'], wd=params['wd'])\n",
    "\n",
    "    print(f'Got losses: {learn.recorder.val_losses} for params {params}')\n",
    "    \n",
    "    # Extract the best score.\n",
    "    best_score = min(learn.recorder.val_losses)\n",
    "    \n",
    "    # Return dictionary with information for evaluation.\n",
    "    return {'loss': best_score, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the search space, iow the ranges of values within which we want the optimiser to look for solutions. For instance, we let it try models with anywhere between 1 and 6 hidden layers (the `num_layers` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space.\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 6, 1),\n",
    "    'layer_size': hp.quniform('layer_size', 25, 5000, 25),\n",
    "    'layer_dropout': hp.loguniform('layer_dropout', np.log(1e-10), np.log(5e-1)),\n",
    "    'emb_drop': hp.uniform('emb_drop', 1e-4, 5e-1),\n",
    "    'wd': hp.uniform('wd', 0.1, 0.9),\n",
    "    'lr': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a random sample from the space of possible sets of hyperparameters, to see that it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt.pyll.stochastic.sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to run the experiments to find the optimal hyperparameters. One experiment consists in training the model for a set number of epochs and then taking the lowest validation loss after any epoch. We can either do this starting from a previously saved state or from a clean slate.\n",
    "\n",
    "The `max_evals` value states the maximum number of experiments to run. The optimiser will run either until the number has been reached or until it has stopped improving the parameters for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to load a previously saved set of parameter trials.\n",
    "bayes_trials = pickle.load(open(\"hyperparam_trials.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to start afresh.\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 25, trials = bayes_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see which hyperparameters were used for the model that got the lowest loss. (Also use the `get_layers` function to see exactly how the layer sizes and dropouts were.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layers(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.main_plot_history(bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.main_plot_histogram(bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from hyperopt import base\n",
    "pl.figure(figsize=(20, 10))\n",
    "plotting.main_plot_vars(bayes_trials, colorize_best=1, columns=3, bandit=base.Domain(objective, space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the trials made so far and continue running the optimizer later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bayes_trials, open(\"hyperparam_trials.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission Predictions\n",
    "\n",
    "Finally, we need to run our model against the test set that is used by the competition's organizers to evaluate the competitors. We save the result to a `submission.csv` file which we'll then upload to Kaggle.\n",
    "\n",
    "_Note: we should only do this at the very end, when we are happy with our hyperparameters. Otherwise, if we change our model based on our results on the public leaderboard, we risk overfitting our model to the 30% of samples used for the public leaderboard, and will fail to generalize for the remaining 70% of samples._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = test_df.copy(); out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set has one row with some missing values (which we don't have in the training set), so let's use the most commonly occuring ones for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.fillna(value={'first_active_monthYear': '2017.0',\n",
    "                     'first_active_monthMonth': '12.0',\n",
    "                     'first_active_monthWeek': '44.0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning -- this takes quite a long time.\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "targets = []\n",
    "for _, row in tqdm(out_df.iterrows()):\n",
    "    targets.append(learn.predict(row)[2].numpy().flatten()[0])\n",
    "out_df['target'] = pd.Series(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['target'].to_csv('submission.csv.zip', header=['target'], index_label='card_id', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
