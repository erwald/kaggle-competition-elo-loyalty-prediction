{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to Classify Elo Customer Loyalty Outliers\n",
    "\n",
    "_Note! If you want to commit any changes to this document, please strip all output (Cell > Current Outputs > Clear, or set up [nbstripout](https://github.com/kynan/nbstripout) as a git filter) from this notebook before doing so. Thanks!_\n",
    "\n",
    "For more detailed descriptions of some of these steps, see the `elo_loyalty_prediction` notebook.\n",
    "\n",
    "PS. For now this model is not very successful when it comes to predicting outliers. Perhaps we can come back to it when we have done more feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_df = pd.read_csv('data/processed/train_with_aggregated_features.csv', index_col='card_id')\n",
    "test_df = pd.read_csv('data/processed/test_with_aggregated_features.csv', index_col='card_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(train_and_validation_df, test_size=0.2, random_state=238923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Issue\n",
    "\n",
    "If we have a look at the loyalty scores that we want to predict for this competition, we'll see that there are a bunch of outliers at around -30 loyalty. (NB. this field is likely normalised to have mean 0 and standard deviation 1, meaning these outliers are probably 0 \\[nan?] in the original data set.)\n",
    "\n",
    "If we could disregard these, our model for predicting the loyalty score would have a much easier time. But of course we don't know which of the incoming fields are outliers in this sense and which aren't. So let's try to make a classifier model to predict whether or not a sample (a `card_id`) is an outlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call any sample with a loyalty score below -25 an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_outlier'] = train_df.target < -25\n",
    "validate_df['is_outlier'] = validate_df.target < -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='is_outlier', data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model\n",
    "\n",
    "Again, for more detailed comments on some of these steps, have a look at the `elo_loyalty_prediction` notebook.\n",
    "\n",
    "We will do some upsampling of the outliers in the training set â€“ basically copying those rows so that they don't drown among all the countless non-outlier samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_train_df = train_df.copy().append([train_df[train_df.is_outlier]] * 10, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = range(len(upsampled_train_df), len(upsampled_train_df) + len(validate_df)); valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['first_active_monthYear',\n",
    "                  'first_active_monthMonth',\n",
    "                  'first_active_monthWeek',\n",
    "                  'first_active_monthIs_quarter_start',\n",
    "                  'first_active_monthIs_year_start',\n",
    "                  'feature_1',\n",
    "                  'feature_2',\n",
    "                  'feature_3',\n",
    "                  'authorized_flag_top',\n",
    "                  'category_1_transaction_top',\n",
    "                  'category_1_merchant_top',\n",
    "                  'category_2_top',\n",
    "                  'category_3_top',\n",
    "                  'category_4_top',\n",
    "                  'subsector_id_transaction_top',\n",
    "                  'subsector_id_merchant_top',\n",
    "                  'city_id_top',\n",
    "                  'state_id_top',\n",
    "                  'purchase_Year_top',\n",
    "                  'purchase_Month_top',\n",
    "                  'purchase_Week_top',\n",
    "                  'purchase_Day_top',\n",
    "                  'purchase_Dayofweek_top',\n",
    "                  'most_recent_sales_range_top',\n",
    "                  'most_recent_purchases_range_top',\n",
    "                  'merch_authorized_flag_top',\n",
    "                  'merch_category_1_transaction_top',\n",
    "                  'merch_category_1_merchant_top',\n",
    "                  'merch_category_2_top',\n",
    "                  'merch_category_3_top',\n",
    "                  'merch_category_4_top',\n",
    "                  'merch_subsector_id_transaction_top',\n",
    "                  'merch_subsector_id_merchant_top',\n",
    "                  'merch_city_id_top',\n",
    "                  'merch_state_id_top',\n",
    "                  'merch_purchase_Year_top',\n",
    "                  'merch_purchase_Month_top',\n",
    "                  'merch_purchase_Week_top',\n",
    "                  'merch_purchase_Day_top',\n",
    "                  'merch_purchase_Dayofweek_top',\n",
    "                  'merch_most_recent_sales_range_top',\n",
    "                  'merch_most_recent_purchases_range_top',]\n",
    "continuous_names = ['first_active_monthElapsed',\n",
    "                    'purchase_amount_sum',\n",
    "                    'purchase_amount_mean',\n",
    "                    'purchase_amount_min',\n",
    "                    'purchase_amount_max',\n",
    "                    'purchase_amount_std',\n",
    "                    'installments_sum',\n",
    "                    'installments_mean',\n",
    "                    'installments_min',\n",
    "                    'installments_max',\n",
    "                    'installments_std',\n",
    "                    'month_lag_mean',\n",
    "                    'month_lag_min',\n",
    "                    'month_lag_max',\n",
    "                    'merchant_id_nunique',\n",
    "                    'state_id_nunique',\n",
    "                    'city_id_nunique',\n",
    "                    'numerical_1_sum',\n",
    "                    'numerical_1_mean',\n",
    "                    'numerical_1_min',\n",
    "                    'numerical_1_max',\n",
    "                    'numerical_1_std',\n",
    "                    'numerical_2_sum',\n",
    "                    'numerical_2_mean',\n",
    "                    'numerical_2_min',\n",
    "                    'numerical_2_max',\n",
    "                    'numerical_2_std',\n",
    "                    'avg_sales_lag3_sum',\n",
    "                    'avg_sales_lag3_mean',\n",
    "                    'avg_sales_lag3_min',\n",
    "                    'avg_sales_lag3_max',\n",
    "                    'avg_sales_lag3_std',\n",
    "                    'avg_sales_lag6_sum',\n",
    "                    'avg_sales_lag6_mean',\n",
    "                    'avg_sales_lag6_min',\n",
    "                    'avg_sales_lag6_max',\n",
    "                    'avg_sales_lag6_std',\n",
    "                    'avg_sales_lag12_sum',\n",
    "                    'avg_sales_lag12_mean',\n",
    "                    'avg_sales_lag12_min',\n",
    "                    'avg_sales_lag12_max',\n",
    "                    'avg_sales_lag12_std',\n",
    "                    'avg_purchases_lag3_sum',\n",
    "                    'avg_purchases_lag3_mean',\n",
    "                    'avg_purchases_lag3_min',\n",
    "                    'avg_purchases_lag3_max',\n",
    "                    'avg_purchases_lag3_std',\n",
    "                    'avg_purchases_lag6_sum',\n",
    "                    'avg_purchases_lag6_mean',\n",
    "                    'avg_purchases_lag6_min',\n",
    "                    'avg_purchases_lag6_max',\n",
    "                    'avg_purchases_lag6_std',\n",
    "                    'avg_purchases_lag12_sum',\n",
    "                    'avg_purchases_lag12_mean',\n",
    "                    'avg_purchases_lag12_min',\n",
    "                    'avg_purchases_lag12_max',\n",
    "                    'avg_purchases_lag12_std',\n",
    "                    'active_months_lag3_sum',\n",
    "                    'active_months_lag3_mean',\n",
    "                    'active_months_lag3_min',\n",
    "                    'active_months_lag3_std',\n",
    "                    'active_months_lag6_sum',\n",
    "                    'active_months_lag6_mean',\n",
    "                    'active_months_lag6_min',\n",
    "                    'active_months_lag6_std',\n",
    "                    'active_months_lag12_sum',\n",
    "                    'active_months_lag12_mean',\n",
    "                    'active_months_lag12_min',\n",
    "                    'active_months_lag12_max',\n",
    "                    'active_months_lag12_std',\n",
    "                    'merchant_category_id_transaction_nunique',\n",
    "                    'merchant_category_id_merchant_nunique',\n",
    "                    'subsector_id_transaction_nunique',\n",
    "                    'subsector_id_merchant_nunique',\n",
    "                    'merchant_group_id_nunique',\n",
    "                    'most_recent_sales_range_nunique',\n",
    "                    'most_recent_purchases_range_nunique',\n",
    "                    'elapsed_since_last_purchase_sum',\n",
    "                    'elapsed_since_last_purchase_mean',\n",
    "                    'elapsed_since_last_purchase_min',\n",
    "                    'elapsed_since_last_purchase_max',\n",
    "                    'elapsed_since_last_purchase_std',\n",
    "                    'elapsed_since_last_merch_purchase_sum',\n",
    "                    'elapsed_since_last_merch_purchase_mean',\n",
    "                    'elapsed_since_last_merch_purchase_min',\n",
    "                    'elapsed_since_last_merch_purchase_max',\n",
    "                    'elapsed_since_last_merch_purchase_std',\n",
    "                    'authorized_flag_Y_ratio',\n",
    "                    'category_1_transaction_N_ratio',\n",
    "                    'category_1_merchant_N_ratio',\n",
    "                    'category_2_1.0_ratio',\n",
    "                    'category_2_3.0_ratio',\n",
    "                    'category_2_4.0_ratio',\n",
    "                    'category_2_2.0_ratio',\n",
    "                    'category_2_5.0_ratio',\n",
    "                    'category_3_A_ratio',\n",
    "                    'category_3_B_ratio',\n",
    "                    'category_3_C_ratio',\n",
    "                    'category_4_N_ratio',\n",
    "                    'purchase_Is_month_start_True_ratio',\n",
    "                    'purchase_Is_month_end_False_ratio',\n",
    "                    'purchase_Year_2017_ratio',\n",
    "                    'most_recent_sales_range_B_ratio',\n",
    "                    'most_recent_sales_range_A_ratio',\n",
    "                    'most_recent_sales_range_C_ratio',\n",
    "                    'most_recent_sales_range_D_ratio',\n",
    "                    'most_recent_sales_range_E_ratio',\n",
    "                    'most_recent_purchases_range_B_ratio',\n",
    "                    'most_recent_purchases_range_C_ratio',\n",
    "                    'most_recent_purchases_range_A_ratio',\n",
    "                    'most_recent_purchases_range_D_ratio',\n",
    "                    'most_recent_purchases_range_E_ratio',\n",
    "                    'merch_purchase_amount_sum',\n",
    "                    'merch_purchase_amount_mean',\n",
    "                    'merch_purchase_amount_min',\n",
    "                    'merch_purchase_amount_max',\n",
    "                    'merch_purchase_amount_std',\n",
    "                    'merch_installments_sum',\n",
    "                    'merch_installments_mean',\n",
    "                    'merch_installments_min',\n",
    "                    'merch_installments_max',\n",
    "                    'merch_installments_std',\n",
    "                    'merch_month_lag_mean',\n",
    "                    'merch_month_lag_min',\n",
    "                    'merch_month_lag_max',\n",
    "                    'merch_merchant_id_nunique',\n",
    "                    'merch_state_id_nunique',\n",
    "                    'merch_city_id_nunique',\n",
    "                    'merch_numerical_1_sum',\n",
    "                    'merch_numerical_1_mean',\n",
    "                    'merch_numerical_1_min',\n",
    "                    'merch_numerical_1_max',\n",
    "                    'merch_numerical_1_std',\n",
    "                    'merch_numerical_2_sum',\n",
    "                    'merch_numerical_2_mean',\n",
    "                    'merch_numerical_2_min',\n",
    "                    'merch_numerical_2_max',\n",
    "                    'merch_numerical_2_std',\n",
    "                    'merch_avg_sales_lag3_sum',\n",
    "                    'merch_avg_sales_lag3_mean',\n",
    "                    'merch_avg_sales_lag3_min',\n",
    "                    'merch_avg_sales_lag3_max',\n",
    "                    'merch_avg_sales_lag3_std',\n",
    "                    'merch_avg_sales_lag6_sum',\n",
    "                    'merch_avg_sales_lag6_mean',\n",
    "                    'merch_avg_sales_lag6_min',\n",
    "                    'merch_avg_sales_lag6_max',\n",
    "                    'merch_avg_sales_lag6_std',\n",
    "                    'merch_avg_sales_lag12_sum',\n",
    "                    'merch_avg_sales_lag12_mean',\n",
    "                    'merch_avg_sales_lag12_min',\n",
    "                    'merch_avg_sales_lag12_max',\n",
    "                    'merch_avg_sales_lag12_std',\n",
    "                    'merch_avg_purchases_lag3_sum',\n",
    "                    'merch_avg_purchases_lag3_mean',\n",
    "                    'merch_avg_purchases_lag3_min',\n",
    "                    'merch_avg_purchases_lag3_max',\n",
    "                    'merch_avg_purchases_lag3_std',\n",
    "                    'merch_avg_purchases_lag6_sum',\n",
    "                    'merch_avg_purchases_lag6_mean',\n",
    "                    'merch_avg_purchases_lag6_min',\n",
    "                    'merch_avg_purchases_lag6_max',\n",
    "                    'merch_avg_purchases_lag6_std',\n",
    "                    'merch_avg_purchases_lag12_sum',\n",
    "                    'merch_avg_purchases_lag12_mean',\n",
    "                    'merch_avg_purchases_lag12_min',\n",
    "                    'merch_avg_purchases_lag12_max',\n",
    "                    'merch_avg_purchases_lag12_std',\n",
    "                    'merch_active_months_lag3_sum',\n",
    "                    'merch_active_months_lag3_mean',\n",
    "                    'merch_active_months_lag3_min',\n",
    "                    'merch_active_months_lag3_max',\n",
    "                    'merch_active_months_lag3_std',\n",
    "                    'merch_active_months_lag6_sum',\n",
    "                    'merch_active_months_lag6_mean',\n",
    "                    'merch_active_months_lag6_min',\n",
    "                    'merch_active_months_lag6_max',\n",
    "                    'merch_active_months_lag6_std',\n",
    "                    'merch_active_months_lag12_sum',\n",
    "                    'merch_active_months_lag12_mean',\n",
    "                    'merch_active_months_lag12_min',\n",
    "                    'merch_active_months_lag12_max',\n",
    "                    'merch_active_months_lag12_std',\n",
    "                    'merch_merchant_category_id_transaction_nunique',\n",
    "                    'merch_merchant_category_id_merchant_nunique',\n",
    "                    'merch_subsector_id_transaction_nunique',\n",
    "                    'merch_subsector_id_merchant_nunique',\n",
    "                    'merch_merchant_group_id_nunique',\n",
    "                    'merch_most_recent_sales_range_nunique',\n",
    "                    'merch_most_recent_purchases_range_nunique',\n",
    "                    'merch_elapsed_since_last_purchase_sum',\n",
    "                    'merch_elapsed_since_last_purchase_mean',\n",
    "                    'merch_elapsed_since_last_purchase_min',\n",
    "                    'merch_elapsed_since_last_purchase_max',\n",
    "                    'merch_elapsed_since_last_purchase_std',\n",
    "                    'merch_category_1_transaction_N_ratio',\n",
    "                    'merch_category_1_merchant_N_ratio',\n",
    "                    'merch_category_2_1.0_ratio',\n",
    "                    'merch_category_2_4.0_ratio',\n",
    "                    'merch_category_2_2.0_ratio',\n",
    "                    'merch_category_2_3.0_ratio',\n",
    "                    'merch_category_2_5.0_ratio',\n",
    "                    'merch_category_3_B_ratio',\n",
    "                    'merch_category_3_A_ratio',\n",
    "                    'merch_category_3_C_ratio',\n",
    "                    'merch_category_4_Y_ratio',\n",
    "                    'merch_category_4_N_ratio',\n",
    "                    'merch_purchase_Is_month_start_True_ratio',\n",
    "                    'merch_purchase_Is_month_end_False_ratio',\n",
    "                    'merch_purchase_Year_2017_ratio',\n",
    "                    'merch_purchase_Year_2018_ratio',\n",
    "                    'merch_most_recent_sales_range_A_ratio',\n",
    "                    'merch_most_recent_sales_range_B_ratio',\n",
    "                    'merch_most_recent_sales_range_D_ratio',\n",
    "                    'merch_most_recent_sales_range_E_ratio',\n",
    "                    'merch_most_recent_sales_range_C_ratio',\n",
    "                    'merch_most_recent_purchases_range_A_ratio',\n",
    "                    'merch_most_recent_purchases_range_B_ratio',\n",
    "                    'merch_most_recent_purchases_range_D_ratio',\n",
    "                    'merch_most_recent_purchases_range_C_ratio',\n",
    "                    'merch_most_recent_purchases_range_E_ratio',]\n",
    "dep_var = 'is_outlier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([upsampled_train_df, validate_df]).reset_index()[category_names + continuous_names + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TabularDataBunch.from_df('data/unzipped',\n",
    "                                df,\n",
    "                                dep_var,\n",
    "                                valid_idx=valid_idx,\n",
    "                                procs=[FillMissing, Categorify, Normalize],\n",
    "                                cat_names=category_names,\n",
    "                                cont_names=continuous_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data,\n",
    "                        layers=[200, 100],\n",
    "                        ps=[1e-1, 5e-1],\n",
    "                        emb_drop=0.04,\n",
    "                        metrics=[accuracy, Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 1e-2, wd=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Now that we have trained our model, lets make some predictions to see whether or not our metrics lie to us.\n",
    "\n",
    "Let's only take those predictions where the model was at least 80% confident that the sample is an outlier, to increase our precision at the expense of recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = [x.numpy() for x in learn.get_preds(DatasetType.Valid)]\n",
    "# Each element in prediction is an array of two values, the likelihood of \n",
    "# `False` (not an outlier) and the likelihood of `True` (an outlier).\n",
    "outlier_predictions = [x[1] > 0.8 for x in predictions]\n",
    "outlier_targets = targets == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({'prediction': outlier_predictions, 'target': outlier_targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[prediction_df.prediction].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate **precision** _(fraction of relevant instances among the retrieved instances)_ and **recall** _(fraction of relevant instances that have been retrieved over the total amount of relevant instances)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_counts = prediction_df[prediction_df.prediction].target.value_counts()\n",
    "false_positives = prediction_counts[0]\n",
    "true_positives = prediction_counts[1]\n",
    "precision = true_positives / (false_positives + true_positives); precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positives = prediction_df.target.value_counts()[1]\n",
    "true_positives = prediction_counts[1]\n",
    "recall = true_positives / total_positives; recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
